{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of a Simple Most Popular Baseline Recommender System\n",
    "Here the demonstration of the baseline model recommending the most popular news is presented.\n",
    "\n",
    "It simply recommends the most popular item in terms of the *click_count* per item.\n",
    "\n",
    "It also includes the evaluation of the recommender model using the metrics *Precision and Recall*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "from parquet_data_reader import ParquetDataReader\n",
    "from models.most_popular import MostPopularRecommender\n",
    "\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "import numpy as np\n",
    "parquet_reader = ParquetDataReader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Split:\n",
      "Train shape: (99210, 4)\n",
      "Test shape: (42513, 4)\n",
      "\n",
      "Time-based Split:\n",
      "Train shape: (99207, 4)\n",
      "Test shape: (42516, 4)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from utils.baseline_processing import process_behavior_data, random_split, time_based_split\n",
    "\n",
    "train_behavior_df = parquet_reader.read_data(\"../../data/train/behaviors.parquet\")\n",
    "test_behaviours_df = parquet_reader.read_data('../../data/validation/behaviors.parquet')\n",
    "\n",
    "# Processes the data\n",
    "combined_df = process_behavior_data(train_behavior_df, test_behaviours_df)\n",
    "\n",
    "# ----- Method 1: Random Split -----\n",
    "train_random, test_random = random_split(combined_df, test_ratio=0.30)\n",
    "print(\"Random Split:\")\n",
    "print(\"Train shape:\", train_random.shape)\n",
    "print(\"Test shape:\", test_random.shape)\n",
    "\n",
    "# ----- Method 2: Time-based Split -----\n",
    "train_time, test_time = time_based_split(combined_df, test_ratio=0.30)\n",
    "print(\"\\nTime-based Split:\")\n",
    "print(\"Train shape:\", train_time.shape)\n",
    "print(\"Test shape:\", test_time.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Random Split of Train/Test for Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 151570:\n",
      "shape: (5,)\n",
      "Series: 'article_id' [i32]\n",
      "[\n",
      "\t9773282\n",
      "\t9775562\n",
      "\t9776234\n",
      "\t9786378\n",
      "\t9775776\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Creates a recommender and fits it to the training data split using the random split method\n",
    "recommender = MostPopularRecommender(behaviors=train_random)\n",
    "recommender.fit()\n",
    "\n",
    "# Test user which is known to have interactions in the data\n",
    "user_id_test = 151570\n",
    "recommendations = recommender.recommend(user_id=user_id_test, n=5)\n",
    "\n",
    "print(f\"Recommendations for user {user_id_test}:\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Time-Based Split Train/Test Recommendations\n",
    "This methods splits the data into the oldest interactions *(test_ratio percent)*\n",
    "are used for testing, and the newest interactions are used for training. This happens after the total data (train and test) has been combined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 151570:\n",
      "shape: (5,)\n",
      "Series: 'article_id' [i32]\n",
      "[\n",
      "\t9776234\n",
      "\t9787465\n",
      "\t9785668\n",
      "\t9780195\n",
      "\t9786378\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Creates a recommender and fits it to the training data split using the time split method\n",
    "recommender2 = MostPopularRecommender(behaviors=train_time)\n",
    "recommender2.fit()\n",
    "\n",
    "recommendations2 = recommender2.recommend(user_id=user_id_test, n=5)\n",
    "\n",
    "print(f\"Recommendations for user {user_id_test}:\")\n",
    "print(recommendations2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Evaluation of the Most Popular (Baseline) Recommender\n",
    "Comparing the two different data-splits for this most popular recommender using the metrics *Precision and Recall*.\n",
    "*FPR* is also printed for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation metrics (precision and recall at k):\n",
      "{'precision@k': np.float64(0.01234896352954218), 'recall@k': np.float64(0.017889268359968683), 'fpr@k': np.float64(0.0021803865997622454)}\n",
      "\n",
      "Evaluation metrics (precision and recall at k):\n",
      "{'precision@k': np.float64(0.0), 'recall@k': np.float64(0.0), 'fpr@k': np.float64(0.004364917949446781)}\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation import evaluate_recommender\n",
    "\n",
    "# Evaluates the recommender using the same data as test data\n",
    "metrics = evaluate_recommender(recommender, test_data=test_random, k=5)\n",
    "print(\"\\nEvaluation metrics (precision and recall at k):\")\n",
    "print(metrics)\n",
    "\n",
    "\n",
    "# Evaluates the recommender using the same data as test data\n",
    "metrics2 = evaluate_recommender(recommender2, test_data=test_time, k=5)\n",
    "print(\"\\nEvaluation metrics (precision and recall at k):\")\n",
    "print(metrics2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
